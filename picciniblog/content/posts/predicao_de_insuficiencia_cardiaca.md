---
author:
  name: "Patrick Piccini"
date: 2022-06-20T13:00:52-01:00
linktitle: Predi√ß√£o de Insufici√™ncia Cardiaca
type:
- post
- posts
title: Predi√ß√£o de Insufici√™ncia Cardiaca
weight: 10
---
!["img"](http://www.bancodasaude.com/cdn/infosaude/article/insuficiencia-cardiaca.jpg)

## Table of Contents
  - [DataSet](#dataset)
  - [Compreendendo o problema](#compreendendo-o-problema)
      - [Informa√ß√µes de atributo](#informa%C3%A7%C3%B5es-de-atributo)
  - [Configura√ß√£o Inicial](#configura%C3%A7%C3%A3o-inicial)
  - [Explora√ß√£o](#explora%C3%A7%C3%A3o)
  - [Limpeza](#limpeza)
  - [Discretiza√ß√£o](#discretiza%C3%A7%C3%A3o)
  - [Visualiza√ß√£o](#visualiza%C3%A7%C3%A3o)
  - [Quais atributos tem rela√ß√£o?](#quais-atributos-tem-rela%C3%A7%C3%A3o)
  - [Distribui√ß√£o de algumas colunas do DataSet](#distribui%C3%A7%C3%A3o-de-algumas-colunas-do-dataset)
  - [Calculo de Insufici√™ncia Cardiaca](#calculo-de-insufici%C3%AAncia-cardiaca)
  - [Inicio de Treinamento de Modelos](#inicio-de-treinamento-de-modelos)
      - [Separa√ß√£o de Dados](#separa%C3%A7%C3%A3o-de-dados)
  - [Desision Tree](#---------desision-tree-train---------)
      - [Medidas de sele√ß√£o de atributo](#medidas-de-sele%C3%A7%C3%A3o-de-atributo)
  - [Randon Fores](#---------randon-forest-train---------)
  - [Logistic Regression](#---------logistic-regression-train---------)
  - [GaussianNB](#---------gaussiannb-train---------)
      - [Calculo do algoritmo](#calculo-do-algoritmo)
  - [Matriz Confus√£o](#matriz-confus%C3%A3o)
  - [Cross-Validation](#cross-validation)
  - [Curva ROC](#curva-roc)
  - [Insigths](#insigths)
---



## Projeto GitHub
[heart-failure-prediction](https://github.com/patrickpiccini/heart-failure-prediction)

Ol√°, meu nome √© Patrick Piccini, e seja bem vindo a mais um projeto de Data Science.

O que iremos ver nesse Projeto:
- üìö DataSet
- üß† Compreendendo o problema
- ‚õè Analise Exploratoria de Dados
- üé≤ Manipula√ß√£o de dados
- üìä Visualiza√ß√£o de dados
- üßÆ Algoritmos de Classifica√ß√£o
- üò± Insigths

## DataSet
[Heart Failure Prediction Dataset - Kaggle](https://www.kaggle.com/datasets/fedesoriano/heart-failure-prediction)

## Compreendendo o problema
As doen√ßas cardiovasculares (DCVs) s√£o a causa n√∫mero 1 de morte em todo o mundo, levando cerca de 17,9 milh√µes de vidas a cada ano, o que representa 31% de todas as mortes em todo o mundo. Quatro das mortes por 5CVD s√£o devido a ataques card√≠acos e derrames, e um ter√ßo dessas mortes ocorre prematuramente em pessoas com menos de 70 anos de idade. A insufici√™ncia card√≠aca √© um evento comum causado por DCV e este conjunto de dados cont√©m 11 caracter√≠sticas que podem ser usadas para prever uma poss√≠vel doen√ßa card√≠aca.

Pessoas com doen√ßa cardiovascular ou com alto risco cardiovascular (devido √† presen√ßa de um ou mais fatores de risco, como hipertens√£o, diabetes, hiperlipidemia ou doen√ßa j√° estabelecida) precisam de detec√ß√£o e gerenciamento precoces, onde um modelo de aprendizado de m√°quina pode ser de grande ajuda.


!["img"](https://lh3.googleusercontent.com/LkeF783CO8iu1R8Q3fB-Kqo9L2x6FWcEYa-5NijcXqgNjaD3gCuixMwzW9ciVlikGNrdI1c1_uemz7xCeqV7I8DCKjl9ZmcKXt3ql9A4Bd-DmIfKZbDFp-yI8O0uvlorXYSbrkuL=s0)

### Informa√ß√µes de atributo
- **Age:** idade do paciente [anos]
- **Sex:** sexo do paciente [M: Masculino, F: Feminino]
- **ChestPainType:** tipo de dor no peito [TA: Angina T√≠pica, ATA: Angina At√≠pica, NAP: Dor N√£o Anginosa, ASY: Assintom√°tica]
- **RestingBP:** press√£o arterial de repouso [mm Hg]
- **Cholesterol:** colesterol s√©rico [mm/dl]
- **FastingBS:** glicemia em jejum [1: se FastingBS > 120 mg/dl, 0: caso contr√°rio]
- **RestingECG:** resultados do eletrocardiograma de repouso [Normal: normal, ST: com anormalidade da onda ST-T (invers√µes da onda T e/ou eleva√ß√£o ou depress√£o do ST > 0,05 mV), HVE: mostrando prov√°vel ou definitiva hipertrofia ventricular esquerda pelos crit√©rios de Estes]
- **MaxHR:** frequ√™ncia card√≠aca m√°xima alcan√ßada [Valor num√©rico entre 60 e 202]
- **ExerciseAngina: angina induzida por exerc√≠cio [S: Sim, N: N√£o]
- **Oldpeak:** pico antigo = ST [Valor num√©rico medido em depress√£o]
- **ST_Slope:** inclina√ß√£o do segmento ST do exerc√≠cio de pico [Up: upsloping, Flat: flat, Down: downsloping]
- **HeartDisease:** classe de sa√≠da [1: doen√ßa card√≠aca, 0: normal]

## Configura√ß√£o Inicial

~~~ python
import numpy as np 
import pandas as pd
import seaborn as sns
from sklearn import tree
import matplotlib.pyplot as plt
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score,precision_score,recall_score,f1_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay, precision_recall_fscore_support

heart_df = pd.read_csv('./dataset/heart.csv', sep=',')
~~~

- Iremos renomear o nome das colunas para Portugu√™s, onde facilitar√° na hora do entendimento da informa√ß√£o dos dados.

~~~ python
columns = {
    'Age': 'Idade',
    'Sex': 'Sexo', 
    'ChestPainType': 'Tipo_Dor_Peito', 
    'RestingBP': 'RepousoPA', 
    'Cholesterol': 'Colesterol', 
    'FastingBS': 'FastingBS',
    'RestingECG': 'RestingECG', 
    'MaxHR': 'Frequencia_Cardiaca_Max', 
    'ExerciseAngina': 'Exercicio_Angina', 
    'Oldpeak': 'Pico_Antigo', 
    'ST_Slope': 'ST_Slope',
    'HeartDisease': 'Doenca_Cardiaca'
}

heart_df = heart_df.rename(columns=columns)
heart_df.head(5)
~~~

!["img1"](/images/insuficiencia_cardiaca/img1.png)

## Explora√ß√£o

- Verificaremos a quantidade de colunas e linhas existentes no DataSet.

~~~ python
print('Colunas: %s' % heart_df.shape[1])
print('Linhas: %s' % heart_df.shape[0])
~~~
- Colunas: 12
- Linhas: 918

Com o comando **"describe"**, iremos obter um resumo de estat√≠sticas descritivas do DataFrame. Isso inclui m√©dia, contagem, desvio padr√£o, percentis e valores m√≠n.-m√°x. de todos os recursos. Com o **".T"** apenas iremos rotacionar o resultado do **"describe"**.

~~~ python
heart_df.describe().T
~~~
!["img2"](/images/insuficiencia_cardiaca/img2.png)

Abaixo veremos mais algumas informa√ß√µes referentes a cada coluna do DataFrame.

~~~ python
heart_df.info()
~~~
!["img3"](/images/insuficiencia_cardiaca/img3.png)

## Limpeza

Percebemos que n√£o existem valores NaN em nosso DataSet, por√©m, existem muitos valores do colesterol igual a 0 (Zero). Visto isso, para n√£o perdermos informa√ß√µes, substituiremos os valores de 0 (Zero) para um valor "Saud√°vel" sendo 130.

Para termos uma visualiza√ß√£o de como ir√° influenciar a limpeza de dados, iremos salvar os dois estados da coluna colesterol, para posteriormente plotarmos um grafico.


~~~ python
print(heart_df.notna().value_counts())
~~~

!["img4"](/images/insuficiencia_cardiaca/img4.png)

~~~ python
colesterol_0 = heart_df.Colesterol
heart_df.Colesterol = heart_df.Colesterol.replace(0, 130)
colesterol_no_0 = heart_df.Colesterol
~~~

## Discretiza√ß√£o

Formar conjuntos de idade para classifica√ß√£o.

~~~ python
print('Idade m√°xima: ',heart_df.Idade.max())
print('Idade MINIMA: ',heart_df.Idade.min())
~~~
- Idade m√°xima:  77
- Idade MINIMA:  28

~~~ python
bins = [0,12,20,60,100]
labels = ['crianca','adolecente','adulto','idoso']
conjuto_idade = pd.cut(heart_df['Idade'].to_numpy(), bins=bins, labels=labels)

heart_df['conjunto_idade'] = conjuto_idade

heart_df.head(3)
~~~

!["img5"](/images/insuficiencia_cardiaca/img5.png)

~~~ python
heart_df.conjunto_idade.value_counts()
~~~

!["img6"](/images/insuficiencia_cardiaca/img6.png)

# Visualiza√ß√£o

Nesse passo da AED iremos plotar alguns gr√°ficos onde consiguiremos ter uma an√°lise das informa√ß√µes um pouco mais din√¢mica, e com isso conseguiremos criar alguns insigths de nossas informa√ß√µes

- Iremos calcular a porcentagem de casos de pessoas com Insufici√™ncia Card√≠acas e sem Insufici√™ncia Card√≠a

~~~ python
print("paciente com Insufici√™ncia Cardiacas:", heart_df.query('Doenca_Cardiaca == 1').shape[0])
print("paciente sem Insufici√™ncia Cardiaca:", heart_df.query('Doenca_Cardiaca == 0').shape[0])

labels = [1,0]
sizes = heart_df['Doenca_Cardiaca'].value_counts()
explode = (0, 0.1, 0, 0)

fig1, ax1 = plt.subplots()
ax1.pie(sizes, labels=labels, autopct='%1.1f%%',shadow=True, startangle=90 ,colors=['#E74C3C','#3498DB'])
ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.show()
~~~
- paciente com Insufici√™ncia Cardiacas: 508
- paciente sem Insufici√™ncia Cardiaca: 410

!["img7"](/images/insuficiencia_cardiaca/img7.png)

## Quais atributos tem rela√ß√£o?

Atrav√©s de uma HeatMap (Mapa de calor), verificaremos quais as rela√ß√µes que os atributos tem com a coluna alvo, que no nosso caso √© a _DoencaCardiaca

Podemos ver que a Doen√ßa Card√≠aca tem grande rela√ß√£o com uma "Pico_Antigo" alta e tambem uma rela√ß√£o com "Idade". H√° uma rela√ß√£o boa com "","FastingBS" e "RepousoPA".

~~~ python
plt.figure(figsize=(10,6))

sns.heatmap(heart_df.corr(), annot=True, cmap ="RdYlBu")
plt.show()
~~~

!["img8"](/images/insuficiencia_cardiaca/img8.png)

## Distribui√ß√£o de algumas colunas do DataSet

Vendo os gr√°ficos plotados, conseguimos perceber o volume de informa√ß√µes sobre determinado valor, de acordo com sua coluna.

Uma coisa que podemos notar no gr√°fico do colesterol, √© que h√° uma grande quantidade de dados com o valor 0 ou negativo. Fazendo um pesquisa r√°pida na internet, entende-se que existe certo consenso de que valores do LDL-Colesterol (¬®colesterol ruim‚Äù) menores que 40 mg/dl no sangue s√£o considerados baixos, entretanto, estudos recentes n√£o demonstraram efeitos colaterais graves mesmo quando esse valor foi reduzido at√© 25mg/dl. Sendo assim, esses dados zeros ou negativos certamente est√£o errados, e com isso, podemos trat√°-los como Outliers.

~~~ python
fig, axes = plt.subplots(2, 3, figsize=(20, 10))
sns.kdeplot(heart_df['Idade'], ax = axes[0, 0] ,shade=True, color='r')
sns.kdeplot(heart_df['RepousoPA'], ax = axes[0, 1], shade=True, color='rebeccapurple')
sns.kdeplot(heart_df['Colesterol'], ax = axes[0, 2], shade=True, color='g')
sns.kdeplot(heart_df['Frequencia_Cardiaca_Max'], ax = axes[1, 0], shade=True, color='darkorange')
sns.kdeplot(heart_df['Pico_Antigo'], ax = axes[1, 1], shade=True, color='blue')
plt.show()
~~~

!["img9"](/images/insuficiencia_cardiaca/img9.png)

Antes de continuarmos, vamos ver a diferen√ßa dos gr√°ficos referente ao Colesterol, visto que tivemos alguns valores modificados no passo de Limpeza dos dados. Apenas relembrando, trocamos os valores 0 do colesterol, para um valor "saud√°vel", sendo esse 130.

~~~ python
fig, axes = plt.subplots(1, 2, figsize=(10, 5))
sns.kdeplot(colesterol_0, ax = axes[0], shade=True, color='r')
sns.kdeplot(colesterol_no_0, ax = axes[1], shade=True, color='g')
plt.show()
~~~

!["img10"](/images/insuficiencia_cardiaca/img10.png)

## Calculo de Insufici√™ncia Cardiaca

~~~ python
fig, axes = plt.subplots(3, 2, figsize=(20, 10))

sns.countplot(x="Sexo", hue="Doenca_Cardiaca", data=heart_df, ax=axes[0, 0] ,palette=['#3498DB','#E74C3C'])
sns.countplot(x="Tipo_Dor_Peito", hue="Doenca_Cardiaca", data=heart_df, ax=axes[0, 1] ,palette=['#3498DB','#E74C3C'])
sns.countplot(x="RestingECG", hue="Doenca_Cardiaca", data=heart_df, ax=axes[1, 0] ,palette=['#3498DB','#E74C3C'])
sns.countplot(x="ST_Slope", hue="Doenca_Cardiaca", data=heart_df, ax=axes[1, 1] ,palette=['#3498DB','#E74C3C'])
sns.countplot(x="conjunto_idade", hue="Doenca_Cardiaca", data=heart_df, ax=axes[2, 0] ,palette=['#3498DB','#E74C3C'])
plt.show()
~~~

!["img11"](/images/insuficiencia_cardiaca/img11.png)

### Grafico Sexo
odemos perceber que Homens tem maiores chances de ter Insuficiencia Card√≠aca mesmo que tenham maior volume de dados. J√° as Mulheres tem grandes chances de N√ÉO ter algum problema card√≠aco. Nota-se que os valores de casos sem a doen√ßa chega a ser 3/4 do conjunto de Mulheres

### Grafico Tipo de dor no peito
- TA: Angina T√≠pica, ATA: Angina At√≠pica, NAP: Dor N√£o Anginosa, ASY: Assintom√°tica

Nota-se que de toda a classe Tipo_Dor_Peito a que mais se destaca √© o classificador ASY, que representa uma dor Assintom√°tica, em outras palavras, uma dor com poucos sintomas, ou pouco visivel. Vemos que o risco de ter insufici√™ncia cardiaca √© extremamente alta contendo esse tipo de dor.

No tipo TA, mesmo tendo um pequeno volume de dados, percebe-se que a quantidade de casos com e sem insufici√™ncia √© quase balanceado. Para esses casos deve-se ter mais aten√ß√£o na hora dos diagn√≥sticos para que o paciente n√£o seja classificado sem a doen√ßa cardiaca.

Devemos perceber que nos tipos NAP e ATA temos um menor volume de dados contendo Insufici√™ncia Card√≠aca comparado com ASY e TA.

### RestingECG
- Resultados do eletrocardiograma de repouso
[Normal: normal, ST: com anormalidade da onda ST-T (invers√µes da onda T e/ou eleva√ß√£o ou depress√£o do ST > 0,05 mV), HVE: mostrando prov√°vel ou definitiva hipertrofia ventricular esquerda pelos crit√©rios de Estes]

dentifica-se que a maioria dos pacientes, independente do resultado do eletrocardiograma, possuem chances de ter algum problema card√≠aco.

### Grafico ST_Stope
- Exame de Teste de Esfor√ßo
- ST_Slope: inclina√ß√£o do segmento ST do exerc√≠cio de pico [Up: upsloping, Flat: flat, Down: downsloping]

Nos resultados do ST_Slope pessoas com segmento ST maiores(UP), n√£o tendem a ter insuficiencia cardiaca, visto que os bastimentos est√£o com um BPM alto.

Se mesmo no Teste de esfor√ßo f√≠sico o segmento ST estiver sem muita varia√ß√£o(Flat), a tend√™ncia a ter insufici√™ncia cardiaca √© bem alta. A mesma coisa quando o segmento ST estiver baixo(Down).

### Conjunto Idade
O conjunto de idade foi criado na parte de discretiza√ß√£o justamente para categorizar cara pessoa por seu devido conjunto de idade sende eles:
- [Crian√ßa - 0 √† 12 
- [Adolecente] - 12 √† 20
- [Adulto] - 20 √† 60 
- [Idoso] - 60 √† 100 

Como podemos perceber, no DataSet n√£o ha nenhum registro de pessoas da categoria "Crian√ßa" e "Adolecente". Nota-se que a 50% de de todos os Adultos tem alguma insufici√™ncia cardiaca, e tambem cerca de 75% dos Idosos tambem foram diagnosticado com essa doen√ßa.

Iremos retirar a coluna de idade, visto que com a nova coluna de "conjunto_idade" poderemos utilizar facilmente no treinamento dos modelos.

~~~ python
heart_df.drop(columns=['Idade'], inplace=True)
~~~


## Inicio de Treinamento de Modelos

!["gif"](https://i0.wp.com/memetizando.com.br/wp-content/uploads/2020/03/meme-eu-na-academia.gif)

### Separa√ß√£o de Dados

Antes de come√ßarmos a criar qualquer modelo, precisaremos separar os dados do Dataframe em dois grupos, um de Treino e outro de Teste.
- Dados de Treino
Os dados de treino s√£o respons√°veis por serem as informa√ß√µes que o Algoritmo de Machine Learnig usara para a cria√ß√£o de um modelo. No nosso caso utilizamos 70% do DataSet para o treinamento.
- Dados de Teste
Os dados de teste s√£o aplicados ao modelo criado, simulando previs√µes reais que o modelo realizar√°, fazendo com que seja verificado o desempenho real do modelo. Utilizaremos 30% do DataSet para Teste.


- Separando dados de Treino e Teste para cria√ß√£o de modelos.
- Alterando o type das informa√ß√µes para 'Category'.

~~~ python
y = heart_df['Doenca_Cardiaca'].values
heart_df.drop(columns=['Doenca_Cardiaca'], inplace=True)

X = heart_df

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0, stratify=y)

for c in X_test.columns:
    if type(X_test[c].iloc[0]) == str:
        X_test[c] = X_test[c].astype('category')
        X_test[c] = X_test[c].cat.codes
        
for c in X_train.columns:
    if type(X_train[c].iloc[0]) == str:
        X_train[c] = X_train[c].astype('category')
        X_train[c] = X_train[c].cat.codes
~~~

## -------- Desision Tree Train --------
![](https://c.tenor.com/sndiWcujL3kAAAAC/cyanide-and-happiness-ladder.gif)

O algoritmo √Årvore de Decis√£o pertence √† fam√≠lia de algoritmos de aprendizado SUPERVISIONADO. Ao contr√°rio de outros algoritmos de aprendizado supervisionado, o algoritmo de √°rvore de decis√£o tamb√©m pode ser usado para resolver problemas de regress√£o e classifica√ß√£o . O objetivo de usar uma √Årvore de Decis√£o √© criar um modelo de treinamento que possa ser usado para prever a classe ou valor da vari√°vel de destino aprendendo regras de decis√£o simples inferidas de dados anteriores (dados de treinamento). Em √Årvores de Decis√£o, para prever um r√≥tulo de classe para um registro, come√ßamos da raiz da √°rvore. Comparamos os valores do atributo root com o atributo do registro. Com base na compara√ß√£o, seguimos o ramo correspondente a esse valor e saltamos para o pr√≥ximo n√≥.

### Medidas de sele√ß√£o de atributo
Se o conjunto de dados consiste em N atributos, decidir qual atributo colocar na raiz ou em diferentes n√≠veis da √°rvore como n√≥s internos √© uma etapa complicada. Apenas selecionar aleatoriamente qualquer n√≥ para ser a raiz n√£o pode resolver o problema. Se seguirmos uma abordagem aleat√≥ria, isso pode nos dar resultados ruins com baixa precis√£o.

Nesses cassos usamos alguns crit√©rios para fazer calculos diferentes na hora da distribui√ß√£o, sendo algum deles:


![img12](/images/insuficiencia_cardiaca/img12.png)
- _**p(i/t)**_  --> peso = quantia de indice da classe/ quantia todal de indices

~~~ python
tree_view = DecisionTreeClassifier(criterion='gini',random_state=0, max_depth=4)

# .fit √© o comando de treinamento(lembre de fitness. o que treina)
model = tree_view.fit(X_train, y_train)
prediction_tree_train = model.predict(X_train)
accuracy = accuracy_score(y_train, prediction_tree_train)
print('Valor Acuracia: ',accuracy)
~~~
#### Valor Acuracia:  0.881619937694704

## -------- Decision Tree Test --------


~~~ python
tree_view_test = DecisionTreeClassifier(criterion='gini',random_state=0, max_depth=4)

prediction_tree_test = model.predict(X_test)
accuracy = accuracy_score(y_test, prediction_tree_test)
print('Valor Acuracia: ',accuracy)
~~~
#### Valor Acuracia:  0.8297101449275363

~~~ python
nome_features = X_test.columns

plt.figure(figsize=(24,11))

plt.title('teste')
tree.plot_tree(model, label=None, node_ids=True, rounded=True, fontsize=9, feature_names=nome_features, filled=True, class_names=['0','1'], proportion=True)
# plt.savefig('decision_tree.png', format='png')
plt.show()
~~~

![img13](/images/insuficiencia_cardiaca/img13.png)

## -------- Randon Forest Train --------

O algoritmo Random Forest √© um tipo de ensemble learning, m√©todo que gera muitos classificadores e combina o seu resultado.

No caso do Random Forest, ele gera v√°rios decision trees, cada um com suas particularidades e combinada o resultado da classifica√ß√£o de todos eles. Essa combina√ß√£o de modelos, torna ele um algoritmo muito mais poderoso do que o Decision Tree

![img14](/images/insuficiencia_cardiaca/img14.png)

~~~ python
SEED=42
randon_forest = RandomForestClassifier(max_depth=5, random_state = SEED)

model_rando_forest = randon_forest.fit(X_train, y_train)
prediction_rf_train = model_rando_forest.predict(X_train)

accuracy = accuracy_score(y_train, prediction_rf_train)
print('Valor Acuracia: ',accuracy)
~~~

#### Valor Acuracia:  0.9003115264797508

## -------- Randon Rorest Test --------

~~~ python
prediction_rf = model_rando_forest.predict(X_test)

accuracy = accuracy_score(y_test, prediction_rf)
print('Valor Acuracia: ',accuracy)
~~~
#### Valor Acuracia:  0.8623188405797102

## -------- Logistic Regression Train --------

Regress√£o log√≠stica pode ser definido como uma t√©cnica estat√≠stica que busca produzir (usando um conjunto de observa√ß√µes) um modelo que possibilita predizer os valores tomados por uma vari√°vel categ√≥rica.

Como no algoritmos da Regress√£o Logistica as vari√°veis s√£o independentes, s√£o analisados os resultados bin√°rios e sendo direcionada a uma das duas categorias. As vari√°veis independentes podem ser categ√≥ricas ou num√©ricas, mas a vari√°vel dependente √© sempre categ√≥rica. Escrito assim:

P(Y=1|X) ou P(Y=0|X)

Isso pode ser usado para calcular a probabilidade de uma palavra ter uma conota√ß√£o positiva ou negativa (0, 1 ou em uma escala intermedi√°ria). Ou pode ser usado para determinar o objeto contido em uma foto (√°rvore, flor, grama, etc.), com cada objeto dado uma probabilidade entre 0 e 1.

![img15](/images/insuficiencia_cardiaca/img15.png)

~~~ python
logistic_regression = LogisticRegression(max_iter = 1000 ,random_state = 0)
model_logistic_regression = logistic_regression.fit(X_train, y_train)
prediction_lr_train = model_logistic_regression.predict(X_train)

y_accuracy = accuracy_score(y_train, prediction_lr_train)
print("Acur√°cia:", y_accuracy)
~~~

#### Acur√°cia: 0.8411214953271028

## -------- Logistic Regression Test --------

~~~ python
prediction_lr_test = model_logistic_regression.predict(X_test)
y_accuracy = accuracy_score(y_test, prediction_lr_test)
print("Acur√°cia:", y_accuracy)
~~~

#### Acur√°cia: 0.8405797101449275

## -------- GaussianNB Train --------

O Teorema de Bayes √© usada para o c√°lculo da probabilidade de um evento dado que outro evento j√° ocorreu, o que √© chamado de probabilidade condicional.

A grande quest√£o do Teorema de Bayes √© que eu preciso ter alguma informa√ß√£o anterior, ou seja, preciso saber que um determinado evento j√° ocorreu e qual a probabilidade desse evento.

#### Calculo do algoritmo

![img16](/images/insuficiencia_cardiaca/img16.png)

~~~ python
gnb = GaussianNB()
modelo_gaucianNB = gnb.fit(X_train, y_train)

preds_naivebaies_train = modelo_gaucianNB.predict(X_train)

y_accuracy = accuracy_score(y_train, preds_naivebaies_train)
print("Acur√°cia:", y_accuracy)
~~~

#### Acur√°cia: 0.8426791277258567

## -------- GaussianNB Train --------

~~~ python
reds_naivebaies_teste = modelo_gaucianNB.predict(X_test)
y_accuracy = accuracy_score(y_test, reds_naivebaies_teste)
print("Acur√°cia:", y_accuracy)
~~~

#### Acur√°cia: 0.8333333333333334

Cria√ß√£o de objeto de classificadores

~~~ python
classifiers = {'Arvore': DecisionTreeClassifier(random_state=0, max_depth=4),
               'Random Forest': RandomForestClassifier(max_depth= 5, random_state = SEED),
               'Naive Bayes': GaussianNB(),
               'Regress√£o Logistica': LogisticRegression(max_iter = 1000 ,random_state = 0),
              }

for c in X_train.columns:
    if X_train[c].dtype == "object":
        X_train[c] = X_train[c].astype('category')
        X_train[c] = X_train[c].cat.codes  

for clf in classifiers.items():
    clf[1].fit(X_train, y_train)
    preds = clf[1].predict(X_test)
    score = accuracy_score(preds, y_test)
    print(f'\n------{clf[0]}------')
    print("Acur√°cia:",accuracy_score(y_test, preds))
    print("Precis√£o:",precision_score(y_test, preds))
    print("Recall:",recall_score(y_test, preds))
    print("F1:",f1_score(y_test, preds))
~~~

![img17](/images/insuficiencia_cardiaca/img17.png)

~~~ python
preds = []
clf_trained = []
names=[]
for clf in classifiers.items():
    clf_atual = clf[1].fit(X_train, y_train)
    clf_trained.append(clf_atual)

    pred_atual=clf[1].predict(X_test)
    preds.append(pred_atual)
    names.append(clf[0])
    
    print(precision_recall_fscore_support(y_test, pred_atual, average='macro'))
~~~

(0.8289915966386554, 0.832855093256815, 0.8290616311094128, None)
(0.8611037056784858, 0.8598756575801052, 0.8604428358526719, None)
(0.8346729708431836, 0.8385142674956161, 0.8330176767676768, None)
(0.8409914404243028, 0.8450502152080345, 0.8401684653856278, None)

### Matriz Confus√£o

![img18](/images/insuficiencia_cardiaca/img18.png)

~~~ python
fig, axs =  plt.subplots(2, 2, figsize=(15, 10))
position = [axs[0,0],axs[0,1],axs[1,0],axs[1,1]]

for i in range(len(classifiers)):
    cm = confusion_matrix(y_test, preds[i], labels=clf_trained[i].classes_)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Ter√°", "N√£o ter√°"])
    position[i].set_title(names[i])
    disp.plot(ax=position[i])
    
plt.show()
~~~

![img19](/images/insuficiencia_cardiaca/img19.png)

## Cross-Validation

A escolha da valida√ß√£o cruzada correta depende do conjunto de dados com o qual voc√™ est√° lidando, e a escolha da valida√ß√£o cruzada em um conjunto de dados pode ou n√£o se aplicar a outros conjuntos de dados. No entanto, existem alguns tipos de t√©cnicas de valida√ß√£o cruzada que s√£o as mais populares e amplamente utilizadas. Esses incluem:

- valida√ß√£o cruzada k-fold.
- valida√ß√£o cruzada estratificada em k-fold A valida√ß√£o cruzada √© dividir os dados de treinamento em algumas partes. Treinamos o modelo em algumas dessas pe√ßas e testamos nas demais.

![img20](/images/insuficiencia_cardiaca/img20.png)

~~~ python
for i in classifiers.items():
    scores_dt = cross_val_score(i[1], X_test, y_test, scoring='accuracy', cv=5)
    print(f'\n---- {i[0]} ----')
    print(scores_dt)
~~~

![img21](/images/insuficiencia_cardiaca/img21.png)

## Curva ROC

~~~ python
ax = plt.gca()
for i in range(len(classifiers)):
    clf = classifiers[names[i]]      
    rfc_disp = RocCurveDisplay.from_estimator(clf, X_test, y_test, ax=ax, alpha=0.7)
plt.show()
    
clf2 = classifiers['Random Forest']
svc_disp = RocCurveDisplay.from_estimator(clf2, X_test, y_test)
svc_disp.plot(ax=ax, alpha=0.8)
plt.show()
~~~

![img22](/images/insuficiencia_cardiaca/img22.png)


## Insigths

Ap√≥s toda a an√°lise do problema e entendimento de algumas hip√≥teses vistas na etapa de Visualiza√ß√£o, criamos o conjunto de treino e testes e aplicamos em diferentes algoritmos. Iniciamos o treinamento dos algoritmos com a tradicional Decision Tree, partindo para Random Forest, GussianNB e Logistic Regression. Para a precis√£o dos resultados dos treinamentos, aplicamos uma camada de Cross-Validation onde os modelos passaram por diferentes conjuntos de dados, resultando em score variados para validarmos a qualidade dos modelos.

Ap√≥s essa valida√ß√£o, identificamos que o modelo Random Forest se destacou com uma Acur√°cia media de 0.88 e uma deriva√ß√£o de 0.05, sendo o melhor resultado da acur√°cia de todos os algoritmos.

Como estamos predizendo um problema de sa√∫de, devemos ter o seguinte pensamento: caso o paciente v√° a um m√©dico √© melhor que ele seja diagnosticado com uma doen√ßa card√≠aca e previna, porem ele N√ÉO tem nenhum problema. Do que ele seja diagnosticado que n√£o tem uma doen√ßa card√≠aca, e, na verdade, ele TEM problema card√≠aco.

Logo, compreendemos que em nossos algoritmos devem conter um BAIXO √≠ndice de falsos negativos(FN). Analisando a matriz confus√£o, nota-se que dentre os quatro algoritmos, apenas um se destaca por conter poucos falsos negativos(FN), a Random Forest. Nota-se que enquanto os outros modelos chegam a 30 ou 32 FN, a Random Forest chega diminuir quase pela metade, chegando aos 18 FN.

Para compararmos as probabilidades de acerto desses Falsos Negativos, devemos olhar para o maior Score de Recall, e novamente a Random Fores se destaca com seus 0.88 de assertividade.

Com isso, entendemos que para predizermos a insufici√™ncia card√≠aca de um paciente, podemos utilizar nosso modelo treinado com Random Forest visto que comparamos os resultados de suas predi√ß√µes, e tamb√©m testamos a qualidade do modelo comprovando a sua efic√°cia em seus resultados.

Espero que tenha aproveitado todo o desenvolvimento do projeto, e que sua leitura tenha agregado conhecimentos.
